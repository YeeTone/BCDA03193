{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d40126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_new_pos = pd.DataFrame()\n",
    "data_new_pos['comment'] = data_pos['comment'].apply(lambda x: str.join('', x))\n",
    "data_new_pos['label'] = 0\n",
    "data_new_pos.reset_index(inplace=True,drop=True)\n",
    "\n",
    "data_new_neg = pd.DataFrame()\n",
    "data_new_neg['comment'] = data_neg['comment'].apply(lambda x: str.join('', x))\n",
    "data_new_neg['label'] = 1\n",
    "data_new_neg.reset_index(inplace=True,drop=True)\n",
    "\n",
    "data_new = pd.concat([data_new_pos,data_new_neg],axis=0)\n",
    "data_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e41fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer()\n",
    "data_new['comment'] = data_new['comment'].apply(jieba.lcut)\n",
    "# jieba分词\n",
    "data_new['comment'] = data_new['comment'].apply(lambda x: str.join(' ', x))\n",
    "# 分词以空格为间隔进行合并，保留语义信息\n",
    "X_comments = vect.fit_transform(data_new['comment']).toarray()\n",
    "# X_comments = X_comments.toarray()\n",
    "word_bag = vect.vocabulary_ # 词袋模型中各词所占的权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec886e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_comments = vect.fit_transform(data_new['comment']).toarray()\n",
    "Y_label = data_new['label']\n",
    "test_ratio = 0.2\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_comments, Y_label, test_size=test_ratio, random_state=1)\n",
    "# 划分训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d05651",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 分类器初始化\n",
    "mlp = MLPClassifier(max_iter = 3)\n",
    "random_forest = RandomForestClassifier()\n",
    "logistic = LogisticRegression()\n",
    "svm = SVC()\n",
    "bayes = GaussianNB()\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# 分类器训练\n",
    "mlp.fit(X_train, Y_train)\n",
    "random_forest.fit(X_train, Y_train)\n",
    "logistic.fit(X_train, Y_train)\n",
    "svm.fit(X_train, Y_train)\n",
    "bayes.fit(X_train, Y_train)\n",
    "knn.fit(X_train, Y_train)\n",
    "\n",
    "# 分类器预测\n",
    "Y_pred_random_forest = random_forest.predict(X_test)\n",
    "Y_pred_mlp = mlp.predict(X_test)\n",
    "Y_pred_logistic = logistic.predict(X_test)\n",
    "Y_pred_svm = svm.predict(X_test)\n",
    "Y_pred_bayes = bayes.predict(X_test)\n",
    "Y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "# 计算准确率并制作相关图表\n",
    "module_names = ['MLP神经网络', '随机森林', '逻辑回归', 'SVM支撑向量机', '朴素贝叶斯', 'KNN近邻']\n",
    "acc_scores = [accuracy_score(Y_pred_random_forest, Y_test),\n",
    "              accuracy_score(Y_pred_mlp, Y_test),\n",
    "              accuracy_score(Y_pred_logistic, Y_test),\n",
    "              accuracy_score(Y_pred_svm, Y_test),\n",
    "              accuracy_score(Y_pred_bayes, Y_test),\n",
    "              accuracy_score(Y_pred_knn, Y_test)]\n",
    "\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"SimHei\"]\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "for i in range(len(x_data)):\n",
    "    autolabel(plt.bar(x_data[i], y_data[i]))\n",
    "plt.title(\"模型种类与准确率柱状图\")\n",
    "plt.xlabel(\"模型类型\")\n",
    "plt.ylabel(\"准确率\")\n",
    "plt.ylimit(0.6, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53361e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "y_pred = Y_pred.astype(np.int_)\n",
    "y_test = Y_test.astype(np.int_)\n",
    "tp = sum(y_pred & y_test) # 计算\n",
    "fp = sum((y_pred == 1) & (y_test == 0))\n",
    "tn = sum((y_pred == 0) & (y_test == 0))\n",
    "fn = sum((y_pred == 0) & (y_test == 1))\n",
    "print('TP = %s, FP = %s, TN = %s, FN = %s' % (tp, fp, tn, fn))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred) # 绘制混淆矩阵\n",
    "cm_display = ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69108e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import math\n",
    "\n",
    "# 计算评估指标\n",
    "accuracy = accuracy_score(Y_pred, Y_test)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "mcc = (tp*tn - fp*fn)/ math.sqrt((tp + fp)*(tp + fn)*(tn + fp)*(tn + fn))\n",
    "\n",
    "print('Accuracy = %s, Precision = %s, Recall = %s, F1_score = %s, MCC = %s' %(accuracy, precision, recall, f1_score, mcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c0f161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "import re\n",
    "\n",
    "data_test = pd.read_excel('../data/test.xlsx') # 读取测试文件\n",
    "comment_origin = data_test['comment'].copy() # 保存评论数据\n",
    "data_test['comment'] = data_test['comment'].apply(lambda x: x.replace('text：',''))\n",
    "data_test['comment'] = data_test['comment'].apply(lambda x: re.sub('[^\\u4E00-\\u9FD5,.?!，。！？、；;:：0-9]+', '', x)) # 数据清洗\n",
    "\n",
    "data_test['comment'] = data_test['comment'].apply(jieba.lcut) # jieba分词\n",
    "data_test['comment'] = data_test['comment'].apply(lambda x: str.join(' ', x)) # 分词后使用空格连接，保留语义信息\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a773e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_comments_test = vect.transform(data_test['comment']).toarray()\n",
    "Y_pred_test = mlp.predict(X_comments_test) # 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5c1dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['target'] = Y_pred_test\n",
    "data_test['comment'] = comment_origin # 恢复评论内容\n",
    "data_test.to_excel('../data/test_out.xlsx', index=False) # 输出到文件"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
