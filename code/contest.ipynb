{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_excel('../data/data.xlsx')\n",
    "data.head()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15920cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "data['comment'] = data['comment'].apply(lambda x: x.replace('text：',''))\n",
    "data['comment'] = data['comment'].apply(lambda x: re.sub('[^\\u4E00-\\u9FD5,.?!，。！？、；;:：0-9]+', '', x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dded65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def make_autopct(values):\n",
    "    def my_autopct(pct):\n",
    "        total = sum(values)\n",
    "        val = int(round(pct*total/100.0))\n",
    "        # 同时显示数值和占比的饼图\n",
    "        return '{p:.2f}% ({v:d})'.format(p=pct,v=val)\n",
    "    return my_autopct\n",
    "\n",
    "num = data['target'].apply(lambda x: '积极' if x == 0 else '消极').value_counts()\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.rcParams['font.sans-serif'] = 'Simhei'\n",
    "plt.pie(num, autopct=make_autopct(num), labels=num.index)\n",
    "plt.title('餐品积极/消极评论标签')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50fa2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import itertools\n",
    "\n",
    "with open('../stopword/stopword-cn.txt','r', encoding = 'utf-8') as f:\n",
    "    stopwords = f.read()\n",
    "    \n",
    "stopwords = stopwords.split()\n",
    "stopwords.append(' ')\n",
    "stopwords.append('\\n')\n",
    "\n",
    "data_neg = data[data['target'] == 1]\n",
    "data_pos = data[data['target'] == 0]\n",
    "\n",
    "data_neg_cut = data_neg['comment'].apply(jieba.lcut)\n",
    "data_neg_cut = data_neg_cut.apply(lambda x : [i for i in x if i not in stopwords])\n",
    "print(data_neg_cut.head())\n",
    "\n",
    "data_pos_cut = data_pos['comment'].apply(jieba.lcut)\n",
    "data_pos_cut = data_pos_cut.apply(lambda x : [i for i in x if i not in stopwords])\n",
    "print(data_pos_cut.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953b84c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def show(wc, fn=None):\n",
    "    plt.imshow(wc)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    if fn is not None:\n",
    "        wc.to_file(fn)\n",
    "\n",
    "freq = pd.Series(list(itertools.chain(*list(data_pos_cut)))).value_counts()\n",
    "mask = np.array(Image.open('../stopword/China.jpg'))\n",
    "wc = WordCloud(scale=4,\n",
    "               width=2500, \n",
    "               height=3000,\n",
    "               font_path='C:/Windows/Fonts/simkai.ttf',\n",
    "               background_color='White', mask=mask)\n",
    "wc2 = wc.fit_words(freq)\n",
    "show(wc2, '../stopword/wordcloud.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ce9f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_pos = pd.Series(list(itertools.chain(*list(data_pos_cut)))).value_counts()\n",
    "freq_neg = pd.Series(list(itertools.chain(*list(data_neg_cut)))).value_counts()\n",
    "\n",
    "wc2_pos = wc.fit_words(freq_pos)\n",
    "show(wc2_pos, '../stopword/wordcloud_pos.png')\n",
    "\n",
    "wc2_neg = wc.fit_words(freq_neg)\n",
    "show(wc2_neg, '../stopword/wordcloud_neg.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4a4c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_pos[0:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa86e5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_day_pos = data_pos['timestamp'].apply(lambda x: x.strftime('%Y-%m')).value_counts()\n",
    "comm_day_pos = comm_day_pos.sort_index()\n",
    "comm_day_neg = data_neg['timestamp'].apply(lambda x: x.strftime('%Y-%m')).value_counts()\n",
    "comm_day_neg = comm_day_neg.sort_index()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(range(len(comm_day_pos)), comm_day_pos, label='积极情绪评价')\n",
    "plt.plot(range(len(comm_day_neg)), comm_day_neg, label='消极情绪评价')\n",
    "plt.xticks(range(len(comm_day_pos)), comm_day_pos.index,rotation=45)\n",
    "plt.grid()\n",
    "plt.title('积极/消极评价随日期变化图')\n",
    "plt.xlabel('日期')\n",
    "plt.ylabel('用户评价数量')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721b95b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_hour_pos = pd.to_datetime(data_pos['timestamp']).apply(lambda x: x.hour).value_counts()\n",
    "comm_hour_pos = comm_hour_pos.sort_index()\n",
    "\n",
    "comm_hour_neg = pd.to_datetime(data_neg['timestamp']).apply(lambda x: x.hour).value_counts()\n",
    "comm_hour_neg = comm_hour_neg.sort_index()\n",
    "\n",
    "plt.plot(comm_hour_pos.index, comm_hour_pos, label='积极情绪评价')\n",
    "plt.plot(comm_hour_neg.index, comm_hour_neg, label='消极情绪评价')\n",
    "plt.title('积极/消极评价随时刻变化图')\n",
    "plt.xticks(ticks=range(0,24))\n",
    "plt.yticks(ticks=range(0,1000,100))\n",
    "plt.xlabel('时刻')\n",
    "plt.ylabel('用户评价数量')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8262ab1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        plt.text(rect.get_x()+rect.get_width()/2.-0.3, 1.03*height, '%s' % int(height), size=18, family=\"Consolas\")\n",
    "\n",
    "best_sellers = data_pos['sellerId'].value_counts().nlargest(10)\n",
    "autolabel(plt.bar(range(len(best_sellers[:10])), best_sellers[:10], label='积极评论数量'))\n",
    "plt.xticks(range(len(best_sellers[:10])), best_sellers[:10].index, rotation=45)\n",
    "plt.title('积极评论最多商家')\n",
    "plt.grid()\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44095b78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_seller_comments = data_pos[data_pos['sellerId'] == 1041]['comment']\n",
    "best_seller_comments_cut = best_seller_comments.apply(jieba.lcut)\n",
    "best_seller_comments_cut = best_seller_comments_cut.apply(lambda x : [i for i in x if i not in stopwords])\n",
    "best_seller_comments_freq = pd.Series(list(itertools.chain(*list(best_seller_comments_cut)))).value_counts()\n",
    "best_seller_comments_freq\n",
    "best_seller_comments_wc2 = wc.fit_words(best_seller_comments_freq)\n",
    "show(best_seller_comments_wc2, '../stopword/wordcloud_best_seller.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897228c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        plt.text(rect.get_x()+rect.get_width()/2.-0.3, 1.03*height, '%s' % int(height), size=18, family=\"Consolas\")\n",
    "\n",
    "worst_sellers = data_neg['sellerId'].value_counts().nlargest(10)\n",
    "autolabel(plt.bar(range(len(worst_sellers[:10])), worst_sellers[:10], label='消极评论数量'))\n",
    "plt.xticks(range(len(worst_sellers[:10])), worst_sellers[:10].index, rotation=45)\n",
    "plt.title('消极评论最多商家')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1e0703",
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_seller_comments = data_neg[data_neg['sellerId'] == 971]['comment']\n",
    "worst_seller_comments_cut = worst_seller_comments.apply(jieba.lcut)\n",
    "worst_seller_comments_cut = worst_seller_comments_cut.apply(lambda x : [i for i in x if i not in stopwords])\n",
    "worst_seller_comments_freq = pd.Series(list(itertools.chain(*list(worst_seller_comments_cut)))).value_counts()\n",
    "worst_seller_comments_wc2 = wc.fit_words(worst_seller_comments_freq)\n",
    "show(worst_seller_comments_wc2, '../stopword/wordcloud_worst_seller.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d40126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_new_pos = pd.DataFrame()\n",
    "data_new_pos['comment'] = data_pos['comment'].apply(lambda x: str.join('', x))\n",
    "data_new_pos['label'] = 0\n",
    "data_new_pos.reset_index(inplace=True,drop=True)\n",
    "\n",
    "data_new_neg = pd.DataFrame()\n",
    "data_new_neg['comment'] = data_neg['comment'].apply(lambda x: str.join('', x))\n",
    "data_new_neg['label'] = 1\n",
    "data_new_neg.reset_index(inplace=True,drop=True)\n",
    "\n",
    "data_new = pd.concat([data_new_pos,data_new_neg],axis=0)\n",
    "data_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e41fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer()\n",
    "data_new['comment'] = data_new['comment'].apply(jieba.lcut)\n",
    "data_new['comment'] = data_new['comment'].apply(lambda x: str.join(' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec886e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_comments = vect.fit_transform(data_new['comment']).toarray()\n",
    "Y_label = data_new['label']\n",
    "test_ratio = 0.1\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_comments, Y_label, test_size=test_ratio, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d05651",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53361e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mlp = MLPClassifier(max_iter = 3)\n",
    "mlp.fit(X_train, Y_train)\n",
    "Y_pred = mlp.predict(X_test)\n",
    "\n",
    "score = accuracy_score(Y_pred, Y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69108e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import math\n",
    "\n",
    "y_pred = Y_pred.astype(np.int_)\n",
    "y_test = Y_test.astype(np.int_)\n",
    "tp = sum(y_pred & y_test)\n",
    "fp = sum((y_pred == 1) & (y_test == 0))\n",
    "tn = sum((y_pred == 0) & (y_test == 0))\n",
    "fn = sum((y_pred == 0) & (y_test == 1))\n",
    "print('TP = %s, FP = %s, TN = %s, FN = %s' % (tp, fp, tn, fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c0f161",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(Y_pred, Y_test)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "mcc = (tp*tn - fp*fn)/ math.sqrt((tp+fp) * (tp + fn) *(tn+fp) *(tn+fn))\n",
    "\n",
    "print('Accuracy = %s, Precision = %s, Recall = %s, F1_score = %s, MCC = %s' %(accuracy, precision, recall, f1_score, mcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a773e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_excel('../data/test.xlsx')\n",
    "comment_origin = data_test['comment'].copy()\n",
    "data_test['comment'] = data_test['comment'].apply(lambda x: x.replace('text：',''))\n",
    "data_test['comment'] = data_test['comment'].apply(lambda x: re.sub('[^\\u4E00-\\u9FD5,.?!，。！？、；;:：0-9]+', '', x))\n",
    "\n",
    "data_test['comment'] = data_test['comment'].apply(jieba.lcut)\n",
    "data_test['comment'] = data_test['comment'].apply(lambda x: str.join(' ', x))\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5c1dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_comments_test = vect.transform(data_test['comment']).toarray()\n",
    "Y_pred_test = mlp.predict(X_comments_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b857753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['target'] = Y_pred_test\n",
    "data_test['comment'] = comment_origin\n",
    "data_test.to_excel('../data/test_out.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a06a914",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
